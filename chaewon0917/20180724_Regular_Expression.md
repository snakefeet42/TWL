#### Regular Expression in Python

#### 01. 배운 내용들 분류하기 

- **(1) 파이썬 문법**
   - 어떤 라이브러리를 쓰더라도 파이썬 문법은 동일하다. 그러니 한 번 익숙해지면 평생 편할 것이다. 
  - 다만, 라이브러리에 따라 어떤 타입과 어떤 함수들이 존재하는지, 표현식의 결과가 어떻게 평가되는지에는 차이가 있다.
    - e.g.) 정수 타입, 스트링, 리스트 등. 

- **(2) 라이브러리**

  - 분야별로 자주 쓰이는 라이브러리가 다르고, 계속 새로 개발되므로 끊임없이 공부해야 한다. 데이터 분석의 경우 Numpy, Pandas, Scipy 등이 _현재_ 자주 쓰인다.
  - 하다보면 새로운 라이브러리를 빠르게 익히는 요령, 원하는 정보를 빠르게 검색하는 요령 등이 점진적으로 발달한다. 

- **(3) 파이썬 안에서 실행되는 _미니 언어_들**

  - 특정 함수의 인자로 특정 형식의 문자열을 넘겨주면 무언가가 실행된다.
    - e.g.) ESS selector : beautifulsoup.select("body > .list > li"), 정규표현식 : re.match(r"(\d+-\d+-\d)")
    - 특징 : 다른 거의 모든 언어에서 동일한 _미니 언어_들이 지원된다. 그러니 한 번 익숙해지면 어디에나 써먹을 수 있다. 

- **(4) 알고리즘과 자료구조**

  - 파이썬 문법과 라이브러리, 미니 언어를 잘 활영하여 컴퓨터에게 내가 원하는 일을 효율적으로 시키는 역할을 한다. 
  - 대부분의 중요한 알고리즘은 이미 개발되어 있으며 자주 쓰이는 알고리즘은 한 줌도 안 된다. 어지간하면 이미 만들어져 있는 것들을 쓰게 될 것이다. (좀 더 본격적으로 프로그래밍을 하고 싶다면 파고들어보자!)

- **(5) 확률과 통계를 통해서...**

  - 세상에서 일어나는 현상들을 정량적으로 이해한다

  - 알려진 정보를 근거로 알려지지 않은 정보를 추측한다

  - 이를 바탕으로 합리적인 의사 결정을 한다

  - 의사 결정에 따른 실행 결과를 정량적으로 평가한다

    - 확률/통계와 프로그래밍의 관계는, 위의 과정들을 알고리즘에 담아내어 일부 혹은 전부를 자동화한다. 
    - 확률/통계를 활용하여 알고리즘을 개발한다. 각종 기계학습 알고리즘, Probabilistic data structure 등  

    

#### 02. A|B Test 이야기 

- H0 (귀무가설; null hypothesis) 

- H1 (대립가설; alternative hypothesis)

- Type I Error : 영향이 없는데 영향이 있는 것으로 판명하는 오류 (false positive)

- Type II Error : 영향이 있는데 없는 것으로 판명하는 오류 (false negative)

  - 우리는 둘 중 어떤 오류를 더 조심해야 할까? 
    - 맥락에 따라 다르다. 
    - P value : 얼마나 차이가 나야 통계적으로 유의미한 차이(statistically significant difference)인지를 파악할 수 있는 기준 
    - 만약 H0이 맞다고 가정했을 때, 기존 안과 새 안의 금액 차이가 평균적으로 0이어야 하는데, 이 실험을 여러 번 반복하면 어떨 때는 0이고, 어떨 때는 0보다 좀 작고, 어떨 때는 0보다 좀 더 클 때도 생길 것이다. 
    - 이런 경우 정규분포를 그린다고 보는데, 이를테면 A 안이 정규분포에서 평균과 가까운 위치의 결과를 내는 것은 평이한 일이지만, 끝쪽에 위치할수록 H0 가설이 참이 아닐 가능성이 높아진다. 그래서 Ronald Fisher가 p < 0.05 일 때, 통계적으로 유의미한 차이가 난다고 이야기한다. 

- 통계적으로는 유의미하지만 효과 크기 (effect size) 가 작다면? 

  - 이를테면, 0.1%의 전환율 상승이 _확실히_ 일어난 경우
    - 하루 평균 1,000명이 구매하고 평균 구매액이 10,000원이라면? 일평균 1,000원의 매출 향상. 쓸 데 없는 일.
    - 하루 평균 100,000명이 구매하고 평균 구매액이 50,000원이라면? 일평균 500,000원의 매출 향상. 이 경우 말이 달라짐. 

- "개선"을 측정할 엄격한 기준이 없으면, 개선이 일어났는지 단정하기 어렵기 때문에 실무에서 데이터 분석의 결과를 평가할 때 필수적으로 A/B 테스트 혹은 그와 유사한 검증이 필요하다.  

   

#### 03. Regual Expression 실습

- **(1) 정규표현식이 무엇인가?**

  - 패턴을 정의하는 언어.
    - 기존에는 뭔가를 찾을 때, '정확히 일치하는 것'을 찾았다. 그런데 정규표현식은 대략 비슷한 것들을 다 찾아준다. 그래서 그 '대략 비슷한 것들'을 정의하는 문법이라고 보면 된다.
  - 구글 문서, 워드, 엑셀, 파이썬, 자바, 자바스크립트 등 어디에나 있음

  - 파이썬 문법에서, '는 String을 열고 닫을 때 사용하므로, 필요에 따라 쌍따옴표와 번갈아 쓴다. 단따옴표와 쌍따옴표가 동시에 쓰일 경우, Back Slash \\를 이용하여 문자화 해준다. 
    - Escape, 탈출; 마크업에서 마크업을 구성하는 어떤 구조를 드러내고 싶을 때 escape 해줘야 한다. 
  - 파이썬 아닌 다른 언어에서는, 이를테면 Javascript는, Back Slash로 문자열을 나타내기도 한다. 언어마다 문자열을 나타내는 방식이 다르다. 
  - Python Regualr Expression에서는, `\d `을 ''숫자''로 인식한다.
  - Python Regular Expression에서는, `\D`을 ''숫자가 아닌 것''으로 인식한다. 
    - `r"\d"`  : raw string. 이 부분의 \\은 문법이 아닌 \\이므로 해석하지 말아라. 
    - 즉, 파이썬에서 정규식을 이용할 때 스트링 앞에 r을 붙여주는 습관을 들이자. 
  - Regular Language의 문법을 기술하는 Expression이라서, Regular Expression.
    - Formal Language (형식 언어)란? 
      - 전산학의 한 분야 중, Programming Languages (컴퓨터언어론) 라는 분야가 있다. 이와 비슷하게, 전산학의 근간을 이루는 분야 중 Formal System 을 연구하는 분야가 있다. 여기에서 Formal Language 란, 알파벳을 어떻게 조합해야 올바른 문법인지를 기술하는 유한 개의 문법이 있다. 
      - 즉, '유한한 알파벳 집합과 '문법을 기술하는 유한한 규칙에 의해 생성되는 문자열의 집합이다.
      - Regular Expression으로 인해서 정의될 수 있는 문장, 그런 종류의 언어들을 '정규 언어'라고 부른다.  
  - Finite state automaton 
  - [Peter Norvig이 Chomsky를 비판한 글](http://norvig.com/chomsky.html)



- **(2) Regular Expression 실습 (오전)**

  - Regular Expression은 앞에서부터 한글자씩 해석한다. 

  - Regular Expression을 넣어야 하는 곳에 일반 String (문자열) 을 넣으면, 자동으로 Match 된다. 

  - Meta Characters 

    - `^` : 문장의 시작
    - `$` : 문장의 끝 
      - `$`, `^`가 Meta Character로 쓰일 때, $, ^가 문자로 들어간 내용을 찾고 싶으면? 
        - '\\'을 사용하여 Escape 해야 함. 
        - 만약 두 개가 쓰였을 경우, \^\^, \\$\\$ 이런 식으로 해 줌.

  - 기타 자주 쓰이는 Meta Characters

    - `.` : 아무거나 한 글자
    - `\d` : 아무 숫자나 한 숫자 ( == [0-9] )
    - `\D` : 숫자가 아닌 것 중 아무거나 한 글자
    - `\s` : 공백 한 글자
    - `\S` : 공백이 아닌 아무거나 한 글자 
    - `n?` : 앞에 무엇(n)이 있거나 또는 없거나 
    - `\b` : 각종 단어의 경계  

  - Character Class

    - `[...]` : 대괄호 안에 있는 내용들 중 하나의 Character과 Match하여 반환한다.
      - e.g.) `sep[ae]r[ae]te`  : 오탈자를 쓸 가능성이 있는 단어들을 찾을 때 활용할 수 있다. 
      - [a-zA-Z],[가-힣],[a-zA-F1-8] 등을 적용해볼 수 있다. 
      - 하이픈은 이렇게 대괄호 안에서, 어떤 범위를 설명해주는 역할로 쓰인다. 대괄호 밖에서는 문자로 인식된다. 

  - Alteration

    - `(...|...|...)` : 괄호 안에 있는 내용들 중 Match되는 것을 전부 반환한다.
      - e.g) `(존경|친애)하는\s\S+[님씨께]` : 존경하는 000님께, 친애하는 000님께 ...

  - Quantifier (양화사 == 수량화시킨 품사(?))

    - `?` : 0개 아니면 1개.
    - `*` : 0개 이상. 
    - `+` : 1개 이상. 
    - `{숫자}` : '숫자'개 이상 
    - `{숫자1, 숫자2}` : '숫자1' 개 이상이거나 '숫자2'개 이상

  - Capture Groups 

    - `(...)` : 어떤 패턴 안에 괄호를 치면, 첫번 째 열리는 괄호와 대응되는 괄호가 첫번 째 Capture Group이 된다. 
    - Capture Group이 하나씩 생길 때마다, 데이터프레임 안에서 데이터를 분류하는 Column 이 하나씩 늘어난다. 
      - 찾아 바꾸기

    ``` python
    text1 = "어쩌고 019-1234-5678, 저쩌고 010-2345-6789"
    text2 = "어쩌고 +82-19-1234-5678, 저쩌고 +82-10-2345-6789"
    ```

    ​	위와 같이 휴대폰번호가 나열된 데이터에, 맨 앞자리 수를 떼고 국가번호를 추가하			고 싶을 때. 즉, 휴대폰번호를 찾아 국가번호가 추가된 번호로 바꾸고 싶을 때.

    ```python
    import re
    re.sub(r'019-1234-5678', r'+82-19-1234-5678', text1)
    ```

    ​	우리는 패턴을 찾고 싶은 것이므로 정규식, 그 중에서도 Capture Group 을 이용해 봅시다.	

    ```python
    import re
    re.sub(r'01(\d)-(\d{4})-(\d{4}), r'+82-1\1-\2-\3', text1)
    ```

  - 모호성?

    - 인공어에는 모호성이 있어서는 안 된다고 배웠다. 그러나… 모호성이 존재한다.
    - e.g.) e-mail 을 matching 하는 패턴의 경우. 
      - `\b[a-z][\w\d_]*@\S+\.com` : 
        - \\b는, 단어 경계이다. 숫자부터 시작하는 아이들과 매칭되는 것을 제거해준다. 
        - 일테면 위에서, `.`의 경우 .을 문자로 인식할지, 표현식의 일부로 인식할지를 기계가 문맥을 고려하여 정할 수 없다. 그래서, 이런 식으로 상황이 모호할 때 기계는 '최대한으로 갈 데 까지 간다'는 입장을 취한다. 이를 두고 greedy하다고 표현한다. 
        - Default 행동이 greedy하기 때문에, quantifier `+` 나 `*` 뒤에 `?`를 붙이는 순간, 이 양화사를 Non-greedy 하게 바꾸라는 명령이 된다. 즉, '최소한으로 갈 수 있는 곳까지만 간다'는 입장을 취하게끔 바꾸어 주느 ㄴ것이다.



#### 04. 컴퓨터는 한글을 어떻게 처리하나?

 - 아스키 코드 (ASCII, American Standard Code for Information Exchange)

    - ​	컴퓨터가 생긴지 얼마 되지 않았을 때, 처음 합의한 텍스트 처리 기준(?). 
       - 총 128개의 문자 체계가 들어 있다. 알파벳 대/소문자, 숫자, 연산기호 등. 미국편향적인 내용으로 구성되어 있다. 2 ** 7 == 128. 옛날 컴퓨터에서 데이터를 처리하는 단위가 보통 8개의 비트로 이루어져 있었다. 
          - 1 Bite = 8 Bits 
          - 하나의 바이트 안에서는, 0~255 까지를 셀 수 있다. 256가지의 수를 셀 수 있는 것. 하나의 바이트 안에서 7개의 비트만 사용하면, 128가지의 수를 사용할 수 있다. 
          - 10진법에서는, 수를 나타내는 단위가 0~9까지 10개가 있다. 
       - 아스키 문자 체계에서는 65가 대문자 A, 95가 소문자 A ,..., 이런 식으로 코드에 특정 문자가 맵핑되어 있다. 

- 그런데 아스키 체계에서는, Chinese, Japanese, Korean (CJK) 문화권의 언어와, Right to Left (R2L) 문화권 문자들을 표현할 수 없다는 문제가 있었다. 

- 한글은 128자가지고는 택도 없기 때문에, 김대중 정권(?) 당시 KSC5601이라는 체계를 만든다. 5601글자를 모아둔 한글용 코드 테이블로, 2 Bite로 한 글자를 표현하는 코드 체계를 만든다. 아스키 코드 체계에서, 맨 앞의 비트는 0으로 정해져있기 때문에 이것을 활용하여 한국의 컴퓨터들이 KSC5601 체계의 구조를 사용하여 맨 앞 비트가 1일 경우 KSC 체계를 사용하는 식으로 텍스트를 표현한다.

- 국제화가 되면서, 하나의 문서가 다국어를 지원할 수 있어야 하는 이슈가 발생. 자연히, 동일한 Bite의 이진법 열이 각 나라 컴퓨터마다 다르게 해석되는 문제가 발생한다. 

- 이후 Unicode Consocium이라는 국제 표준화 기구가 생기고, 세계 모든 PC에서 텍스트가 충돌하지 않는 표준화된 체계를 만드는 움직임이 생긴다. 이렇게 탄생한 Unicode 체계는 16진법을 따르며, 각각의 코드에서 초성/중성/종성을 뽑아내거나, 하나의 성을 바꾸거나 하는 연산을 설계할 수 있다. 

  - 한국어 조사 처리 함수 
  - Unicode 는 이러한 글자와 숫자를 맵핑해 놓은 거대한 테이블이고, 이것을 인코딩하여 목적에 맞게 부호화하는 시스템이 UTF-8 이다. Unicode 를 UTF-8 방식으로 저장하여 전송할 경우, 영미권(라틴 계열 문자를 사용하는)에서는 아스키 코드와 유사한 방식으로 전송한다. 

  

#### 05. 기타 내용들…  

- Symbolic AI, GOFAI (Good Old-Fashioned Artificial Intelligence)
  - 인간이 논리적으로 절차를 잘 기술하여 최대한 논리적으로 행동하는 지능을 만들어내고자 한 움직임.
- 인공신경망 (Artificial Neural Network)
  - 뇌를 본따서, 한 쪽에 익명 Node 들을 가져다 놓고, 마지막 끝에 출력 Node 들을 가져다 둔다. 인풋과 아웃풋을 주고, 그 사이의 올바른 입-출력 경로를 이루는 연결고리(망)에 가중치를 주고, 그렇지 않은 망은 약화시키는 방법으로 구성을 강화시키는 방법으로 이루어짐. 
  - 그 망의 작동 방식이나 구조는 상대적으로 중요하지 않으나, 어떤 입력을 넣었을 때 원하는 답이 나오면 좋다고 보는 관점. 
  - 통계적 접근과 통하는 방법. 
- 두 방법 사이를 오가면서 유행하다가, 최근의 인공신경망이 비교할 수 없을 정도로 기능이 향상되어 Deep Neural Net 이라고 불리운다. 두 분야에서 계속해서 대립이 일어나고 있다.
  - 인간은 생득적인, 본성에 의한 언어에 대한 이해력이나 논리를 가지고 있다는 것이 Chomsky의 관점이다. Chomsky는 미국 언어권에서 태어난 아이가 미국 언어의 문법 규칙을 완벽히 익히려면 통계적으로 엄청나게 많은 문장을 들었어야 하는데, 택도 없이 적은 문장을 듣고 나서도 영어 문법을 익힌다는 것은 이미 문법을 올바르게 구사하기 위해 필요한 정보의 상당량을 가진 상태에서 언어 자극을 어느 정도만 받으면 가능하다는 이론.
  - 이와 반대로 행동주의자들은 인간이 백지상태로 태어난다는 관점이다. 이러한 관점이 ANN 측의 관점과 상통한다. 
  - Chomsky가 이는 불가능하다는 입장을 취했고 그것이 시대를 대변한 적이 있었음. 최근에는 엔지니어들이 DNN이 가능해지고 있는 흐름을 만들어내면서, 언어학과 컴퓨터공학 사이에서 상보적인 정보교환이 활발하게 이루어지고 있다. 